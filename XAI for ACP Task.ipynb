{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNoGU9GlbwriKy114E7fgh/"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# XAI using LIME for Social ACP"],"metadata":{"id":"MblIsqqmYvBS"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"4NOdylLxVsvd"},"outputs":[],"source":["import lime\n","import lime.lime_text\n","from transformers import BertTokenizer\n","from sklearn.preprocessing import LabelEncoder\n","import numpy as np\n","import pandas as pd\n","import tensorflow as tf\n","from transformers import TFBertForSequenceClassification\n","import os\n","import matplotlib.pyplot as plt\n","\n","# Load the BERT model using Hugging Face Transformers\n","model_path = 'acp_models/AWARE_SocialNetworkingResults'\n","model = TFBertForSequenceClassification.from_pretrained(model_path)\n","\n","# Load your dataset\n","df = pd.read_csv(\"AWARE_Social_Networking.csv\")\n","\n","# Encode categorical labels\n","label_encoder = LabelEncoder()\n","df['encoded_label'] = label_encoder.fit_transform(df['sentiment'])\n","\n","# Initialize the BERT tokenizer and set max sequence length\n","tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n","max_length = 256\n","\n","# Function to predict using the BERT model\n","def predict_proba(texts):\n","    tokenized_texts = tokenizer(texts, padding=True, truncation=True, return_tensors='tf', max_length=max_length)\n","\n","    # Extract necessary tensors from BatchEncoding\n","    input_ids = tokenized_texts['input_ids']\n","    token_type_ids = tokenized_texts['token_type_ids']\n","    attention_mask = tokenized_texts['attention_mask']\n","\n","    # Make predictions\n","    predictions = model.predict({'input_ids': input_ids, 'token_type_ids': token_type_ids, 'attention_mask': attention_mask})\n","    logits = predictions['logits']\n","    probabilities = tf.nn.softmax(logits, axis=1).numpy()\n","    return probabilities\n","\n","# Initialize LIME explainer\n","explainer = lime.lime_text.LimeTextExplainer(class_names=label_encoder.classes_)\n","\n","# Specify the path to save explanation PNGs\n","save_path = 'acp_models/AWARE_Social_Networkingfinalresult/lime_explanationsup'\n","\n","# Create the directory if it doesn't exist\n","os.makedirs(save_path, exist_ok=True)\n","\n","# Select a few samples for explanation\n","samples_to_explain = df.sample(n=5)['sentence'].tolist()\n","\n","# List to store evaluations\n","evaluations = []\n","\n","# Explain predictions with LIME\n","for idx, sample in enumerate(samples_to_explain):\n","    # LIME explanation\n","    exp = explainer.explain_instance(sample, predict_proba, num_features=5, top_labels=0)\n","\n","    # Get the predicted class label\n","    predicted_class_index = np.argmax(predict_proba([sample]))\n","    predicted_class = label_encoder.classes_[predicted_class_index]\n","\n","    # Evaluate local fidelity\n","    perturbed_text = ' '.join(np.random.permutation(sample.split()))\n","    perturbed_proba = predict_proba([perturbed_text])[0]\n","    original_proba = predict_proba([sample])[0]\n","    local_fidelity = 1.0 - tf.reduce_mean(tf.abs(perturbed_proba - original_proba))\n","\n","    # Evaluate perturbation stability\n","    perturbed_predictions = [predict_proba([' '.join(np.random.permutation(sample.split()))])[0] for _ in range(500)]\n","    perturbed_predictions = tf.stack(perturbed_predictions)\n","    stability = 1.0 - tf.reduce_mean(tf.abs(perturbed_predictions - original_proba))\n","\n","    # Save results to the evaluations list\n","    evaluations.append({\n","        'Sample Index': idx,\n","        'Sample Text': sample,\n","        'Predicted Class': predicted_class,\n","        'Local Fidelity': local_fidelity.numpy(),\n","        'Perturbation Stability': stability.numpy()\n","    })\n","\n","    # Customize the title of the explanation\n","    title = f\"Local Explanation - Predicted Class: {predicted_class}\"\n","\n","    # Create a Matplotlib figure\n","    exp_fig = exp.as_pyplot_figure(label=exp.available_labels()[0])\n","    exp_fig.suptitle(title, y=0.95)  # Set the title using Matplotlib\n","\n","    # Remove the default title\n","    exp_fig.gca().set_title('')\n","\n","    # Save the figure as PNG\n","    img_path = os.path.join(save_path, f'lime_explanation_{idx}.png')\n","    exp_fig.savefig(img_path, bbox_inches='tight')\n","\n","    # Display the Matplotlib figure\n","    plt.show(exp_fig)\n","\n","    # Display text with highlighted explanations in notebook\n","    exp.show_in_notebook(text=True)\n","\n","    print(f\"LIME explanation saved as {img_path}\")\n","\n","# Display the evaluations\n","print(\"\\nSample Evaluations:\")\n","print(pd.DataFrame(evaluations))\n"]},{"cell_type":"markdown","source":["# XAI using LIME for Productivity ACP\n"],"metadata":{"id":"_bUiVuqBYnaa"}},{"cell_type":"code","source":["import lime\n","import lime.lime_text\n","from transformers import BertTokenizer\n","from sklearn.preprocessing import LabelEncoder\n","import numpy as np\n","import pandas as pd\n","import tensorflow as tf\n","from transformers import TFBertForSequenceClassification\n","import os\n","import matplotlib.pyplot as plt\n","\n","# Load the BERT model using Hugging Face Transformers\n","model_path = 'acp_models/AWARE_Productivityfinalresult'\n","model = TFBertForSequenceClassification.from_pretrained(model_path)\n","\n","# Load your dataset\n","df = pd.read_csv(\"AWARE_Productivity.csv\")\n","\n","# Encode categorical labels\n","label_encoder = LabelEncoder()\n","df['encoded_label'] = label_encoder.fit_transform(df['sentiment'])\n","\n","# Initialize the BERT tokenizer and set max sequence length\n","tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n","max_length = 256\n","\n","# Function to predict using the BERT model\n","def predict_proba(texts):\n","    tokenized_texts = tokenizer(texts, padding=True, truncation=True, return_tensors='tf', max_length=max_length)\n","\n","    # Extract necessary tensors from BatchEncoding\n","    input_ids = tokenized_texts['input_ids']\n","    token_type_ids = tokenized_texts['token_type_ids']\n","    attention_mask = tokenized_texts['attention_mask']\n","\n","    # Make predictions\n","    predictions = model.predict({'input_ids': input_ids, 'token_type_ids': token_type_ids, 'attention_mask': attention_mask})\n","    logits = predictions['logits']\n","    probabilities = tf.nn.softmax(logits, axis=1).numpy()\n","    return probabilities\n","\n","# Initialize LIME explainer\n","explainer = lime.lime_text.LimeTextExplainer(class_names=label_encoder.classes_)\n","\n","# Specify the path to save explanation PNGs\n","save_path = 'acp_models/AWARE_Productivityfinalresult/lime_explanationsup'\n","\n","# Create the directory if it doesn't exist\n","os.makedirs(save_path, exist_ok=True)\n","\n","# Select a few samples for explanation\n","samples_to_explain = df.sample(n=5)['sentence'].tolist()\n","\n","# List to store evaluations\n","evaluations = []\n","\n","# Explain predictions with LIME\n","for idx, sample in enumerate(samples_to_explain):\n","    # LIME explanation\n","    exp = explainer.explain_instance(sample, predict_proba, num_features=5, top_labels=0)\n","\n","    # Get the predicted class label\n","    predicted_class_index = np.argmax(predict_proba([sample]))\n","    predicted_class = label_encoder.classes_[predicted_class_index]\n","\n","    # Evaluate local fidelity\n","    perturbed_text = ' '.join(np.random.permutation(sample.split()))\n","    perturbed_proba = predict_proba([perturbed_text])[0]\n","    original_proba = predict_proba([sample])[0]\n","    local_fidelity = 1.0 - tf.reduce_mean(tf.abs(perturbed_proba - original_proba))\n","\n","    # Evaluate perturbation stability\n","    perturbed_predictions = [predict_proba([' '.join(np.random.permutation(sample.split()))])[0] for _ in range(500)]\n","    perturbed_predictions = tf.stack(perturbed_predictions)\n","    stability = 1.0 - tf.reduce_mean(tf.abs(perturbed_predictions - original_proba))\n","\n","    # Save results to the evaluations list\n","    evaluations.append({\n","        'Sample Index': idx,\n","        'Sample Text': sample,\n","        'Predicted Class': predicted_class,\n","        'Local Fidelity': local_fidelity.numpy(),\n","        'Perturbation Stability': stability.numpy()\n","    })\n","\n","    # Customize the title of the explanation\n","    title = f\"Local Explanation - Predicted Class: {predicted_class}\"\n","\n","    # Create a Matplotlib figure\n","    exp_fig = exp.as_pyplot_figure(label=exp.available_labels()[0])\n","    exp_fig.suptitle(title, y=0.95)  # Set the title using Matplotlib\n","\n","    # Remove the default title\n","    exp_fig.gca().set_title('')\n","\n","    # Save the figure as PNG\n","    img_path = os.path.join(save_path, f'lime_explanation_{idx}.png')\n","    exp_fig.savefig(img_path, bbox_inches='tight')\n","\n","    # Display the Matplotlib figure\n","    plt.show(exp_fig)\n","\n","    # Display text with highlighted explanations in notebook\n","    exp.show_in_notebook(text=True)\n","\n","    print(f\"LIME explanation saved as {img_path}\")\n","\n","# Display the evaluations\n","print(\"\\nSample Evaluations:\")\n","print(pd.DataFrame(evaluations))\n"],"metadata":{"id":"6ig7mgsHYdmq"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# XAI using LIME for Games ACP\n"],"metadata":{"id":"WajBLoC7Y4Ig"}},{"cell_type":"code","source":["import lime\n","import lime.lime_text\n","from transformers import BertTokenizer\n","from sklearn.preprocessing import LabelEncoder\n","import numpy as np\n","import pandas as pd\n","import tensorflow as tf\n","from transformers import TFBertForSequenceClassification\n","import os\n","import matplotlib.pyplot as plt\n","\n","# Load the BERT model using Hugging Face Transformers\n","model_path = 'acp_models/AWARE_GamesResults'\n","model = TFBertForSequenceClassification.from_pretrained(model_path)\n","\n","# Load your dataset\n","df = pd.read_csv(\"AWARE_GAMES.csv\")\n","\n","# Encode categorical labels\n","label_encoder = LabelEncoder()\n","df['encoded_label'] = label_encoder.fit_transform(df['sentiment'])\n","\n","# Initialize the BERT tokenizer and set max sequence length\n","tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n","max_length = 256\n","\n","# Function to predict using the BERT model\n","def predict_proba(texts):\n","    tokenized_texts = tokenizer(texts, padding=True, truncation=True, return_tensors='tf', max_length=max_length)\n","\n","    # Extract necessary tensors from BatchEncoding\n","    input_ids = tokenized_texts['input_ids']\n","    token_type_ids = tokenized_texts['token_type_ids']\n","    attention_mask = tokenized_texts['attention_mask']\n","\n","    # Make predictions\n","    predictions = model.predict({'input_ids': input_ids, 'token_type_ids': token_type_ids, 'attention_mask': attention_mask})\n","    logits = predictions['logits']\n","    probabilities = tf.nn.softmax(logits, axis=1).numpy()\n","    return probabilities\n","\n","# Initialize LIME explainer\n","explainer = lime.lime_text.LimeTextExplainer(class_names=label_encoder.classes_)\n","\n","# Specify the path to save explanation PNGs\n","save_path = 'acp_models/AWARE_Gamesfinalresult/lime_explanationsup'\n","\n","# Create the directory if it doesn't exist\n","os.makedirs(save_path, exist_ok=True)\n","\n","# Select a few samples for explanation\n","samples_to_explain = df.sample(n=5)['sentence'].tolist()\n","\n","# List to store evaluations\n","evaluations = []\n","\n","# Explain predictions with LIME\n","for idx, sample in enumerate(samples_to_explain):\n","    # LIME explanation\n","    exp = explainer.explain_instance(sample, predict_proba, num_features=5, top_labels=0)\n","\n","    # Get the predicted class label\n","    predicted_class_index = np.argmax(predict_proba([sample]))\n","    predicted_class = label_encoder.classes_[predicted_class_index]\n","\n","    # Evaluate local fidelity\n","    perturbed_text = ' '.join(np.random.permutation(sample.split()))\n","    perturbed_proba = predict_proba([perturbed_text])[0]\n","    original_proba = predict_proba([sample])[0]\n","    local_fidelity = 1.0 - tf.reduce_mean(tf.abs(perturbed_proba - original_proba))\n","\n","    # Evaluate perturbation stability\n","    perturbed_predictions = [predict_proba([' '.join(np.random.permutation(sample.split()))])[0] for _ in range(500)]\n","    perturbed_predictions = tf.stack(perturbed_predictions)\n","    stability = 1.0 - tf.reduce_mean(tf.abs(perturbed_predictions - original_proba))\n","\n","    # Save results to the evaluations list\n","    evaluations.append({\n","        'Sample Index': idx,\n","        'Sample Text': sample,\n","        'Predicted Class': predicted_class,\n","        'Local Fidelity': local_fidelity.numpy(),\n","        'Perturbation Stability': stability.numpy()\n","    })\n","\n","    # Customize the title of the explanation\n","    title = f\"Local Explanation - Predicted Class: {predicted_class}\"\n","\n","    # Create a Matplotlib figure\n","    exp_fig = exp.as_pyplot_figure(label=exp.available_labels()[0])\n","    exp_fig.suptitle(title, y=0.95)  # Set the title using Matplotlib\n","\n","    # Remove the default title\n","    exp_fig.gca().set_title('')\n","\n","    # Save the figure as PNG\n","    img_path = os.path.join(save_path, f'lime_explanation_{idx}.png')\n","    exp_fig.savefig(img_path, bbox_inches='tight')\n","\n","    # Display the Matplotlib figure\n","    plt.show(exp_fig)\n","\n","    # Display text with highlighted explanations in notebook\n","    exp.show_in_notebook(text=True)\n","\n","    print(f\"LIME explanation saved as {img_path}\")\n","\n","# Display the evaluations\n","print(\"\\nSample Evaluations:\")\n","print(pd.DataFrame(evaluations))\n"],"metadata":{"id":"D_uiZhJMZopR"},"execution_count":null,"outputs":[]}]}